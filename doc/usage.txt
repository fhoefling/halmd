Usage
*****

Prerequisites
=============

To allow the shell to find the program and its required libraries, set these
environment variables in the shell initialization file (e.g. ~/.bashrc)::

  export PATH="$HOME/usr/bin${PATH+:$PATH}"
  export LD_LIBRARY_PATH="$HOME/usr/lib${LD_LIBRARY_PATH+:$LD_LIBRARY_PATH}"


Getting started
===============

Simulation backends
-------------------

ljgpu implements various simulation backends using dynamically loaded plugins.

.. glossary::

   host backend
     A single-threaded soft-sphere molecular dynamics simulation.

     This is a straight-forward reference implementation using cell and
     neighbour lists.

     D. C. Rapaport,
     *The Art of Molecular Dynamics Simulation*,
     Cambridge University Press, 2004

   gpu_square backend
     A naive soft-sphere molecular dynamics simulation for the GPU.

     This is a straight-forward implementation without cell or neighbour lists.
     Simulation time therefore **scales quadratically** with the system size.

   gpu_cell backend
     An optimised soft-sphere molecular dynamics simulation for the GPU.

     This implementation for the GPU uses fixed-size cell lists, which yields
     a speedup over the CPU of order 10.

     J. A. van Meel, A. Arnold, D. Frenkel, S.F. Portegies Zwart and R. G. Belleman,
     *Harvesting graphics power for MD simulations*,
     `Simulation, Taylor & Francis, 2008, 34, 259-266 <http://dx.doi.org/10.1080/08927020701744295>`_

   gpu_neighbour backend
     An optimised soft-sphere molecular dynamics simulation for the GPU.

     This implementation for the GPU uses fixed-size cell and neighbour lists, which yields
     a speedup over the CPU of order 100.

     P. H. Colberg and F. HÃ¶fling,
     *Accelerating glassy dynamics using graphics processing units*,
     in preparation

     J. A. Anderson, C. D. Lorenz and A. Travesset,
     *General purpose molecular dynamics simulations fully implemented on graphics processing units*,
     `Journal of Computational Physics, 2008, 227, 5342-5359 <http://dx.doi.org/10.1016/j.jcp.2008.01.047>`_

     H. Sagan,
     *A three-dimensional Hilbert curve*,
     `International Journal of Mathematical Education in Science and Technology, Taylor & Francis, 1993, 24, 541-545 <http://dx.doi.org/10.1080/0020739930240405>`_

   hardsphere backend
     A single-threaded, event-based hard-sphere molecular dynamics simulation.

     This is a straight-forward reference implementation using cell lists.

     M. P. Allen, D. Frenkel and J. Talbot,
     *Molecular dynamics simulation using hard particles*,
     `Computer Physics reports, 1989, 9, 301-353 <http://dx.doi.org/10.1016/0167-7977(89)90009-9>`_

     S. Miller and S. Luding,
     *Event-driven molecular dynamics in parallel*,
     `Journal of Computational Physics, 2004, 193, 306-316 <http://dx.doi.org/10.1016/j.jcp.2003.08.009>`_


Program parameters
------------------

ljgpu has three ways of accepting program parameters:

* pass directly as command line parameters
* read from parameter input file [INI format]
* read from HDF5 data file, optionally resuming from a prior trajectory

Options are described in the command line help::

  ljgpu --help


Multi-GPU machines
==================

If your NVIDIA driver version comes with the nvidia-smi tool, set all CUDA
devices to *compute exclusive mode* to restrict use to one process per device::

  sudo nvidia-smi --gpu=0 --compute-mode-rules=1
  sudo nvidia-smi --gpu=1 --compute-mode-rules=1

ljgpu will then choose the first available CUDA device if the ``--device``
option is not given. Note that this works with all CUDA versions, not only
CUDA >= 2.2.


If your NVIDIA driver version does not support the nvidia-smi tool, or if you
wish not to set the devices to compute exclusive mode, the nvlock tool
accompanying ljgpu may be used to exclusively assign a GPU to each process::

  nvlock ljgpu [...]


For optimal exploitation of a multi-GPU machine, a job scheduler is highly
recommended, e.g. `SLURM <https://computing.llnl.gov/linux/slurm/>`_.

